{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection with Machine Learning Models\n",
    "## Model Training\n",
    "### Ian Heung\n",
    "\n",
    "In the previous notebook, we made 5 different training datasets that feature various sampling methods to mitigate the effects of the class imbalance in the original dataset. We will now train the training data on various models and evaluate which sampling method will create a model that yields the best results on our testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choices\n",
    "\n",
    "We will choose 4 model types: \n",
    "\n",
    "- Decision Trees\n",
    "- KNNs (K-Nearest Neighbors)\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "\n",
    "Below are some of the Pros and Cons for each model type:\n",
    "\n",
    "| Model | Pros | Cons |\n",
    "|-|-|-|\n",
    "| **Decision Trees** | - Handles non-linearity <br> - Provides insight into feature importance | - Prone to overfitting <br> - Bias towards features with more levels <br> - Instability with small changes in data |\n",
    "| **K-Nearest Neighbors (KNN)** | - Simple methodology <br>  - Flexible with distance metrics | - Computationally intensive <br> - Sensitive to noise <br> - Not as good with higher dimensionalities|\n",
    "| **Logistic Regression** | - Ideal for binary classification <br>  - Regularization available | - Assumes linear decision boundary <br> - Not ideal for large feature sets |\n",
    "| **Support Vector Machines (SVM)** | - Effective in high-dimensional spaces <br> - Versatile kernels for non-linearity <br> - Robust to overfitting | - Computationally expensive <br> - Hyperparameter selection and tuning can be challenging|\n",
    "\n",
    "In addition to each of the model types, a grid search for hyperparamter tuning will be performed each fitting where possible. Since we are testing all the differently sampled datasets on each model type, we need to be aware of the dataset size, since there are some models that will be less effective due to computational costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives vs False Negatives\n",
    "\n",
    "If we think back to the problem we are trying to solve, we need to focus on the recall of our model at identifying fraudulent transactions. We want to minimize the amount of actual fraudulent transactions that do not get classified correctly, even at the cost of misclassifying non-fraudulent transactions as fraudulent. This means we want to prioritize minimizing **false negatives**. Below is a confusion matrix that is an example case that shows a sample model that predicts whether transactions are fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_matrix = np.array([[100, 5],  # True Positives, False Negative\n",
    "                             [10, 50]])  # False Positive, True Negative\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "cax = ax.matshow(example_matrix, cmap='Blues')\n",
    "\n",
    "plt.colorbar(cax)\n",
    "\n",
    "for (i, j), value in np.ndenumerate(example_matrix):\n",
    "    ax.text(j, i, f'{value}', ha='center', va='center', color='black', fontsize=14)\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Positive (Fraud)', 'Negative (Non-Fraud)'])\n",
    "ax.set_yticklabels(['Positive (Fraud)', 'Negative (Non-Fruad)'])\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is good at detecting true positives (fraudulent cases). It might seem counterintuitive that fraudulent cases are considered positive, but because this is the class we particularly care about, it is labeled as the positive class. However, we see that there are 5 fraud cases incorrectly classified as non-fraud by the model, these are the **false negatives**. This is concerning because it means the model failed to detect these fraudulent cases. Additionally, we observe that the model has classified 10 non-fraud cases as fraud, these are the **false positives**. This outcome is preferable, as we would rather be more cautious and flag potential fraud cases, even if there is no actual fraud. In this situation, we prefer to have more false positives, which are non-fraud cases classified as fraud, while minimizing false negatives, which are fraud cases are classified as non-fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load in our training data for all 5 sampling cases. If we recall, these were the sampling cases each number corresponded to:\n",
    "\n",
    "1. No Balancing at All\n",
    "2. Undersampling\n",
    "3. Oversampling\n",
    "4. Mixed Sampling (Undersampling + Oversampling)\n",
    "5. Mixed Sampling + Outlier Removal\n",
    "\n",
    "Since we have 5 sets of data of different sizes for sampling case 4 and 5, we will store each dataset in a list corresponding to the sampling method. We will use a for loop to iterate through the list during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "directory = 'data'\n",
    "\n",
    "# 1 - unsampled data\n",
    "xtrain_1 = pd.read_csv(os.path.join(directory, 'xtrain.csv'))\n",
    "ytrain_1 = pd.read_csv(os.path.join(directory, 'ytrain.csv'))\n",
    "\n",
    "# convert to numpy arrays\n",
    "xtrain_1 = xtrain_1.values\n",
    "ytrain_1 = ytrain_1.values\n",
    "\n",
    "# 2 - undersampled data\n",
    "xtrain_2 = pd.read_csv(os.path.join(directory, 'xtrain_undersampled.csv'))\n",
    "ytrain_2 = pd.read_csv(os.path.join(directory, 'ytrain_undersampled.csv'))\n",
    "\n",
    "xtrain_2 = xtrain_2.values\n",
    "ytrain_2 = ytrain_2.values\n",
    "\n",
    "# 3 - oversampled data\n",
    "xtrain_3 = pd.read_csv(os.path.join(directory, 'xtrain_oversampled.csv'))\n",
    "ytrain_3 = pd.read_csv(os.path.join(directory, 'ytrain_oversampled.csv'))\n",
    "\n",
    "xtrain_3 = xtrain_3.values\n",
    "ytrain_3 = ytrain_3.values\n",
    "\n",
    "# 4 - mix sampled data\n",
    "mix_sample_sizes = np.load(os.path.join(directory, 'mix_sample_sizes.npy')) # for parsing filenames of case 4 and 5\n",
    "xtrain_4 = []\n",
    "ytrain_4 = []\n",
    "\n",
    "# iterate mix_sample_sizes that were saved \n",
    "for n in mix_sample_sizes:\n",
    "    x = pd.read_csv(os.path.join(directory, f'xtrain_mix_{n}.csv'))\n",
    "    y = pd.read_csv(os.path.join(directory, f'ytrain_mix_{n}.csv'))\n",
    "    \n",
    "    x = x.values\n",
    "    y = y.values\n",
    "    \n",
    "    xtrain_4.append(x)\n",
    "    ytrain_4.append(y)\n",
    "\n",
    "# 5 - filtered mix sampled data\n",
    "xtrain_5 = []\n",
    "ytrain_5 = []\n",
    "\n",
    "for n in mix_sample_sizes:\n",
    "    x = pd.read_csv(os.path.join(directory, f'xtrain_mix_{n}.csv'))\n",
    "    y = pd.read_csv(os.path.join(directory, f'ytrain_mix_{n}.csv'))\n",
    "    \n",
    "    x = x.values\n",
    "    y = y.values\n",
    "    \n",
    "    xtrain_5.append(x)\n",
    "    ytrain_5.append(y)\n",
    "    \n",
    "# test data\n",
    "xtest = pd.read_csv(os.path.join(directory, 'xtest.csv'))\n",
    "ytest = pd.read_csv(os.path.join(directory, 'ytest.csv'))\n",
    "\n",
    "xtest = xtest.values\n",
    "ytest = ytest.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "We will define our model training pipeline here. The range of the grid search terms has been determined through multiple training tests.\n",
    "\n",
    "When running computationally intensive models like KNN and SVM, it would take hours for the model to train and sometimes cause my local device to crash. Therefore, the model training pipeline is configured in a way where it will not train the KNN and SVM models if the input data size exceeds 50,000 datapoints. The grid search is also not as comprehensive as it could be, but I have selected a sensible range of hyperparameters to tune.\n",
    "\n",
    "For the scoring metric, our main goal is to maximize recall for the positive class (fraudulent transactions) while also ensuring the model does not default to predicting only the positive class for all transactions. To achieve this, I created a custom metric that combines the recall for the positive class with the macro F1 score. This composite score helps ensure that we don’t overfit purely on recall while also maintaining a balanced model across both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom scoring function\n",
    "def composite_scorer(y_true, y_pred):\n",
    "    rec_pos_class = recall_score(y_true, y_pred, pos_label=1) # positive class recall\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro') # macro f1 score\n",
    "    \n",
    "    # combine the two scores and divide by 2\n",
    "    comp_score = (rec_pos_class + f1_macro) / 2\n",
    "\n",
    "    return comp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training pipeline\n",
    "def train_models(xtrain, ytrain):\n",
    "    \n",
    "    # intialize our model types\n",
    "    decision_trees = DecisionTreeClassifier()\n",
    "    knn = KNeighborsClassifier()\n",
    "    logistic = LogisticRegression()\n",
    "    svm = SVC()\n",
    "\n",
    "    # decision trees grid search hyperparameters\n",
    "    dt_hyperparams = {\n",
    "            \"max_depth\": [10, 20, 30],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_leaf_nodes\": [10, 20, 30]\n",
    "        }\n",
    "\n",
    "    # knn grid search hyperparameters\n",
    "    knn_hyperparams = {\n",
    "        'n_neighbors': [2, 5, 10, 15],\n",
    "        'weights': ['uniform', 'distance']\n",
    "        }\n",
    "\n",
    "    # logistic regression hyperparameters\n",
    "    logistic_hyperparams = {\n",
    "        \"penalty\": ['l1', 'l2'], \n",
    "        'C': [0.01, 0.1, 1, 10]\n",
    "        }\n",
    "\n",
    "    # support vector machines hyperparameters\n",
    "    svm_hyperparams = {\n",
    "        'C': [0.1, 1, 10], \n",
    "        'kernel': ['rbf', 'poly', 'linear']\n",
    "        }\n",
    "\n",
    "    # custom scorer\n",
    "    composite_score = make_scorer(composite_scorer)\n",
    "    \n",
    "    # put into a triplet for parsing into for loop\n",
    "    models = [('Decision Trees', decision_trees, dt_hyperparams), \n",
    "            ('KNN', knn, knn_hyperparams), \n",
    "            ('Logistic Regression', logistic, logistic_hyperparams),\n",
    "            ('Support Vector Machines', svm, svm_hyperparams)]\n",
    "    \n",
    "    # save results to a dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # iterate list of triplets\n",
    "    for name, model, grid in models:\n",
    "        # change cross validation fold based on dataset size\n",
    "        if len(xtrain) >= 50000:\n",
    "            cv_folds = 3\n",
    "        else:\n",
    "            cv_folds = 5\n",
    "            \n",
    "        # skip training for KNN and SVM on very large datasets\n",
    "        if (len(xtrain)) < 50000 or (name != 'KNN' and name != 'Support Vector Machines'):\n",
    "            clf = GridSearchCV(\n",
    "                estimator=model, \n",
    "                param_grid=grid,\n",
    "                scoring=composite_score, \n",
    "                cv=cv_folds,  \n",
    "                verbose=3, \n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            print(\"Training\", name, \"Model\")\n",
    "            \n",
    "            # fit training data                    \n",
    "            classifier = clf.fit(xtrain, ytrain)\n",
    "            \n",
    "            print(\"Validation fitting with best custom score:\", clf.best_score_)\n",
    "            print(\"Best parameters found from grid search: \", clf.best_params_)\n",
    "            print()\n",
    "\n",
    "            results[name] = [classifier.best_estimator_, clf.best_score_, clf.best_params_]\n",
    "        else:\n",
    "            results[name] = 'Skipped'\n",
    "            print(name, 'Model skipped due to long training time')\n",
    "            print()\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - No Sampling\n",
    "\n",
    "The dataset is too large, so we don't train KNN and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.8374964956876765\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 10}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.7565832811762699\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_1 = train_models(xtrain_1, ytrain_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9052884654601948\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 30}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.92695205059139\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.924304176187017\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9211829591267605\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_2 = train_models(xtrain_2, ytrain_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Oversampling\n",
    "\n",
    "The dataset is too large, so we don't train KNN and SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.9648722081775909\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.9308753940855788\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_3 = train_models(xtrain_3, ytrain_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Mixed Sampling\n",
    "\n",
    "The dataset size vaires. It is too large for the first two mixed sampling sets, so we don't train KNN and SVM models on them. We do train KNN and SVM models on the remaining 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.9653929871277565\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.9312176218912898\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.9652958659968148\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.9306701942247354\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9611757712226515\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9974278975522702\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.932160094683146\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9715300189866015\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9564087043679574\n",
      "Best parameters found from grid search:  {'criterion': 'gini', 'max_depth': 30, 'max_leaf_nodes': 30}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9922824906014596\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9250996822063641\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9438810270131117\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9410637411349269\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 30, 'max_leaf_nodes': 20}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9823963201244246\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9258798584189792\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9274263508904509\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 - 227450\n",
    "results_4_0 = train_models(xtrain_4[0], ytrain_4[0]) # No KNN, SVM\n",
    "# 1 - 71926\n",
    "results_4_1 = train_models(xtrain_4[1], ytrain_4[1]) # No KNN, SVM\n",
    "# 2 - 22744\n",
    "results_4_2 = train_models(xtrain_4[2], ytrain_4[2])\n",
    "# 3 - 7192\n",
    "results_4_3 = train_models(xtrain_4[3], ytrain_4[3])\n",
    "# 4 - 2274\n",
    "results_4_4 = train_models(xtrain_4[4], ytrain_4[4])\n",
    "\n",
    "results_4 = [results_4_0, results_4_1, results_4_2, results_4_3, results_4_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Mixed Sampling + Outlier Removal\n",
    "\n",
    "Same as 4 - Mixed Sampling, the dataset size vaires. The same training methods are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.9653929871277565\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.9312176218912898\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Validation fitting with best custom score: 0.9652958659968148\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "KNN Model skipped due to long training time\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Validation fitting with best custom score: 0.9306701942247354\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Support Vector Machines Model skipped due to long training time\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9611757712226515\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9974278975522702\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.932160094683146\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9715300189866015\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9565478299292373\n",
      "Best parameters found from grid search:  {'criterion': 'gini', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9922824906014596\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9250996822063641\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9438810270131117\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Training Decision Trees Model\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Validation fitting with best custom score: 0.9408441520291191\n",
      "Best parameters found from grid search:  {'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 20}\n",
      "\n",
      "Training KNN Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9823963201244246\n",
      "Best parameters found from grid search:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Training Logistic Regression Model\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Validation fitting with best custom score: 0.9258798584189792\n",
      "Best parameters found from grid search:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Training Support Vector Machines Model\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Validation fitting with best custom score: 0.9274263508904509\n",
      "Best parameters found from grid search:  {'C': 10, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0 - 227450\n",
    "results_5_0 = train_models(xtrain_5[0], ytrain_5[0]) # No KNN, SVM\n",
    "# 1 - 71926\n",
    "results_5_1 = train_models(xtrain_5[1], ytrain_5[1]) # No KNN, SVM\n",
    "# 2 - 22744\n",
    "results_5_2 = train_models(xtrain_5[2], ytrain_5[2])\n",
    "# 3 - 7192\n",
    "results_5_3 = train_models(xtrain_5[3], ytrain_5[3])\n",
    "# 4 - 2274\n",
    "results_5_4 = train_models(xtrain_5[4], ytrain_5[4])\n",
    "\n",
    "results_5 = [results_5_0, results_5_1, results_5_2, results_5_3, results_5_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation Results\n",
    "\n",
    "The models are now all trained. Lets see the validation results of all the sampling and model types by looking at the performance on validation data, as well as the hyperparemeters selected from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a function for easy viewing of our validation results\n",
    "def print_results(results):\n",
    "    # reference each model the dictonary keys \n",
    "    for k in results.keys():\n",
    "        # If a model is skipped, this is the print output\n",
    "        if results[k] == 'Skipped':\n",
    "            print(\"Model: \", k)\n",
    "            print(results[k])\n",
    "            print()\n",
    "        else:\n",
    "            print(\"Model: \", k)\n",
    "            print(\"Best Score: \", results[k][1])\n",
    "            print(\"Best Parameters: \", results[k][2])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Decision Trees\n",
      "Best Score:  0.8374964956876765\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 10}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.7565832811762699\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(results_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Decision Trees\n",
      "Best Score:  0.9052884654601948\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.92695205059139\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.924304176187017\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9211829591267605\n",
      "Best Parameters:  {'C': 10, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Decision Trees\n",
      "Best Score:  0.9648722081775909\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9308753940855788\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Mixed Sampling\n",
    "There is a scrollable output since the output gets truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Datapoints 227450\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9653929871277565\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9312176218912898\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n",
      "\n",
      "Number of Datapoints 71926\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9652958659968148\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9306701942247354\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n",
      "\n",
      "Number of Datapoints 22744\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9611757712226515\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9974278975522702\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.932160094683146\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9715300189866015\n",
      "Best Parameters:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "Number of Datapoints 7192\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9564087043679574\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 30, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9922824906014596\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9250996822063641\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9438810270131117\n",
      "Best Parameters:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "Number of Datapoints 2274\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9410637411349269\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 30, 'max_leaf_nodes': 20}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9823963201244246\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9258798584189792\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9274263508904509\n",
      "Best Parameters:  {'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for loop to iterate through the different mixed sampling models\n",
    "for i in range(len(results_4)):\n",
    "    print(\"Number of Datapoints\", mix_sample_sizes[i])\n",
    "    print_results(results_4[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Mixed Sampling + Outlier Removal\n",
    "There is a scrollable output since the output gets truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Datapoints 227450\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9653929871277565\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9312176218912898\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n",
      "\n",
      "Number of Datapoints 71926\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9652958659968148\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Skipped\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9306701942247354\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Skipped\n",
      "\n",
      "\n",
      "Number of Datapoints 22744\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9611757712226515\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9974278975522702\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.932160094683146\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9715300189866015\n",
      "Best Parameters:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "Number of Datapoints 7192\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9565478299292373\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 10, 'max_leaf_nodes': 30}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9922824906014596\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9250996822063641\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9438810270131117\n",
      "Best Parameters:  {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "Number of Datapoints 2274\n",
      "Model:  Decision Trees\n",
      "Best Score:  0.9408441520291191\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 20, 'max_leaf_nodes': 20}\n",
      "\n",
      "Model:  KNN\n",
      "Best Score:  0.9823963201244246\n",
      "Best Parameters:  {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      "Model:  Logistic Regression\n",
      "Best Score:  0.9258798584189792\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "Model:  Support Vector Machines\n",
      "Best Score:  0.9274263508904509\n",
      "Best Parameters:  {'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for loop to iterate through the different mixed sampling models\n",
    "for i in range(len(results_5)):\n",
    "    print(\"Number of Datapoints\", mix_sample_sizes[i])\n",
    "    print_results(results_5[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our intial preview of the models, even the base case no sampling models performed decently despite the data imbalance, with 70-80% on our custom weighted score. But we also see some models that have scores that seem too high, close to 98-99%, which is an indication of overfitting. Most of the results hover around 92-96%. Because of the size of some datasets, we were not able to train KNN and SVM models on those datasets. This was one of the tradeoffs we had to make when using these two models due to their high computational costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Now that we have trained our models, it is time to evaluate them on our testing data. We will evaluate all the models and generate predictions on the test data. We create a function to parse in our model training results and filter out the models that were skipped due to computational limitations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate and make predictions on test data\n",
    "def evaluate_results(results, xtest):\n",
    "    ypred_array = []\n",
    "    for k in results.keys():\n",
    "        if results[k] == 'Skipped':\n",
    "            ypred_array.append([])\n",
    "        else:\n",
    "            model = results[k][0]\n",
    "            ypred = model.predict(xtest)\n",
    "            ypred_array.append(ypred)\n",
    "    return ypred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds_1 = evaluate_results(results_1, xtest)\n",
    "ypreds_2 = evaluate_results(results_2, xtest)\n",
    "ypreds_3 = evaluate_results(results_3, xtest)\n",
    "\n",
    "# append the predictions for each mixed sampled dataset into a list\n",
    "ypreds_4 = []\n",
    "for i in range(len(results_4)):\n",
    "     ypreds_4.append(evaluate_results(results_4[i], xtest))\n",
    "     \n",
    "ypreds_5 = []\n",
    "for i in range(len(results_5)):\n",
    "     ypreds_5.append(evaluate_results(results_5[i], xtest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to visualize how our model is doing is to use a confusion matrix. Because we skipped training KNN and SVM models for large datasets, we need to add an option to display 2 models instead of 4 for each sampling set. The following custom function will produce a confusion matrix plot and save it to a plots folder. Both standard and row normalized confusion matrices will be created. I chose to normalize by row because it represents the class recall. We are not as concerend about precision in this scenario, as we want to prioritze the recall of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(ypreds, title, filename, num_plots, normalize, show_plot):\n",
    "    if num_plots == 2:\n",
    "        ypreds = ypreds[0:3:2]\n",
    "        model_types = [\"Decision Trees\", \"Logistic Regression\"]\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 2x1 grid of subplots\n",
    "\n",
    "        # iterate each subplot\n",
    "        for m, ax in enumerate(axes.ravel()):\n",
    "            cm = confusion_matrix(ytest, ypreds[m], normalize='true' if normalize else None)\n",
    "            cm = cm[[1, 0], :]  # reorder the confusion matrix to flip rows\n",
    "            cm = cm[:, [1, 0]]  # reorder the confusion matrix to flip columns\n",
    "\n",
    "            cax = ax.matshow(cm, cmap='Blues')\n",
    "\n",
    "            # annotate cells with the number of instances or percentages\n",
    "            for (i, j), value in np.ndenumerate(cm):\n",
    "                if normalize:\n",
    "                    ax.text(j, i, f'{value:.4f}', ha='center', va='center', color='black', fontsize=15)\n",
    "                else:\n",
    "                    ax.text(j, i, f'{value}', ha='center', va='center', color='black', fontsize=15)\n",
    "\n",
    "            ax.set_xlabel('Predicted', fontsize=12)\n",
    "            ax.set_ylabel('Actual', fontsize=12)\n",
    "\n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_xticklabels(['Fraud', 'Non-Fraud'])  # flipped order\n",
    "            ax.set_yticklabels(['Fraud', 'Non-Fraud'])  # flipped order\n",
    "\n",
    "            ax.set_title(f'{model_types[m]} Confusion Matrix')\n",
    "\n",
    "    elif num_plots == 4:        \n",
    "        model_types = [\"Decision Trees\", \"KNN\", \"Logistic Regression\", \"SVM\"]\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # 2x2 grid of subplots\n",
    "\n",
    "        for m, ax in enumerate(axes.ravel()):\n",
    "            cm = confusion_matrix(ytest, ypreds[m], normalize='true' if normalize else None)\n",
    "            cm = cm[[1, 0], :]  # reorder the confusion matrix to flip rows\n",
    "            cm = cm[:, [1, 0]]  # reorder the confusion matrix to flip columns\n",
    "\n",
    "            cax = ax.matshow(cm, cmap='Blues')\n",
    "\n",
    "            # annotate cells with the number of instances or percentages\n",
    "            for (i, j), value in np.ndenumerate(cm):\n",
    "                if normalize:\n",
    "                    ax.text(j, i, f'{value:.4f}', ha='center', va='center', color='black', fontsize=15)\n",
    "                else:\n",
    "                    ax.text(j, i, f'{value}', ha='center', va='center', color='black', fontsize=15)\n",
    "\n",
    "            ax.set_xlabel('Predicted', fontsize=12)\n",
    "            ax.set_ylabel('Actual', fontsize=12)\n",
    "\n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_xticklabels(['Fraud', 'Non-Fraud'])  # flipped order\n",
    "            ax.set_yticklabels(['Fraud', 'Non-Fraud'])  # flipped order\n",
    "\n",
    "            ax.set_title(f'{model_types[m]} Confusion Matrix')\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid number of plots\")\n",
    "        return\n",
    "        \n",
    "    fig.suptitle(title, fontsize = 16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save plot\n",
    "    directory = 'plots'\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    plt.savefig(os.path.join(directory, f'{filename}.png'))\n",
    "    \n",
    "    # option to show plot in output\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ypreds_1, '1 - No Sampling' , '1_no_sampling', 2, normalize=False, show_plot=False)\n",
    "plot_confusion_matrix(ypreds_1, '1 - No Sampling (Normalized)' , '1_no_sampling_norm', 2, normalize=True, show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ypreds_2, '2 - Undersampling', '2_undersampling', 4, normalize=False, show_plot=False)\n",
    "plot_confusion_matrix(ypreds_2, '2 - Undersampling (Normalized)' , '2_undersampling_norm', 4, normalize=True, show_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ypreds_3, '3 - Oversampling', '3_oversampling', 2, normalize=False, show_plot=False)\n",
    "plot_confusion_matrix(ypreds_3, '3 - Oversampling (Normalized)', '3_oversampling_norm', 2, normalize=True, show_plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more plots for *4 - mixed sampling* and *5 - mixed sampling with outliers removed* since they have 5 sampling sets for each sampling case. We use for loops to plot multiple confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through ypreds_4 and assign filename based on num data points\n",
    "for i in range(len(ypreds_4)): \n",
    "    # our num_plots changes if the sampling set did not train KNN and SVM models\n",
    "    if len(ytrain_4[i]) >= 50000:\n",
    "        num_plots = 2\n",
    "    else:\n",
    "        num_plots = 4\n",
    "    \n",
    "    # do not show plots as will fill up whole screen\n",
    "    plot_confusion_matrix(ypreds_4[i], f'4 - Mixed Sampling ({mix_sample_sizes[i]} Training Points)', f'4_mix_sampling_{mix_sample_sizes[i]}', num_plots, normalize=False, show_plot=False) \n",
    "    plot_confusion_matrix(ypreds_4[i], f'4 - Mixed Sampling (Normalized, {mix_sample_sizes[i]} Training Points)', f'4_mix_sampling_norm_{mix_sample_sizes[i]}', num_plots, normalize=True, show_plot=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through ypreds_5 and assign filename based on num data points\n",
    "for i in range(len(ypreds_5)): \n",
    "    # our num_plots changes if the sampling set did not train KNN and SVM models\n",
    "    if len(ytrain_5[i]) >= 50000:\n",
    "        num_plots = 2\n",
    "    else:\n",
    "        num_plots = 4\n",
    "    \n",
    "    # do not show plots as will fill up whole screen\n",
    "    plot_confusion_matrix(ypreds_5[i], f'5 - Mixed Sampling + Outliers Removed ({mix_sample_sizes[i]} Training Points)', f'5_filtered_sampling_{mix_sample_sizes[i]}', num_plots, normalize=False, show_plot=False)\n",
    "    plot_confusion_matrix(ypreds_5[i], f'5 - Mixed Sampling + Outliers Removed (Normalized, {mix_sample_sizes[i]} Training Points)', f'5_filtered_sampling_norm_{mix_sample_sizes[i]}', num_plots, normalize=True, show_plot=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices\n",
    "\n",
    "Using confusion matrices is one of the best ways to see how our models are classifying data on a class specific basis. In our situation, we have many confusion matrices for each sampling dataset, and also the option to show standard or normalized values. As such, only relevant confusion matrices will be shown to avoid overloading the notebook with too many plots. All the confusion matrices can be seen in the `plots` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - No Sampling and 3 - Oversampling\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>1 - No Sampling</th>\n",
    "    <th>1 - No Sampling (Normalized)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"plots/1_no_sampling.png?v=3\" alt=\"1\" width=\"600\"/></td>\n",
    "    <td><img src=\"plots/1_no_sampling_norm.png?v=3\" alt=\"1_norm\" width=\"600\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>3 - Oversampling</th>\n",
    "    <th>3 - Oversampling (Normalized)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"plots/3_oversampling.png?v=3\" alt=\"3\" width=\"600\"/></td>\n",
    "    <td><img src=\"plots/3_oversampling_norm.png?v=3\" alt=\"3_norm\" width=\"600\"/></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN and SVM models were not able to be trained for the following two sampling cases due to computational limits.\n",
    "\n",
    "As expected, the models that trained without using any sampling have overfitting because of the class imbalance. Even though it is the base case, we see that the model is very good at detecting non-fraudulent cases. It has the highest recall for detecting non-fraudulent transactions. However, because of the overfitting, it is not as sensitive to fraudulent transactions, with the decision trees model only correctly classifying **76.55%** of fraud transactions and the logistic regression model correctly classifying **58.16%** of fraud transactions.\n",
    "\n",
    "When we oversampled the data, we saw a large improvement in the results for the decision trees and logistic regression models. The decision trees model correctly classified **87.76%** of fraudulent transactions, while the logistic regression model correctly classified **91.84%** of fraudulent transactions. However, because we used SMOTE, the training data is not a direct reflection of the true data, so the models are likely good at generalizing but cannot correctly identify edge cases due to the usage of artificial data during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Undersampling\n",
    "\n",
    "  <table>\n",
    "  <tr>\n",
    "    <th>2 - Undersampling</th>\n",
    "    <th>2 - Undersampling (Normalized)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"plots/2_undersampling.png?v=3\" alt=\"2\" width=\"600\"/></td>\n",
    "    <td><img src=\"plots/2_undersampling_norm.png?v=3\" alt=\"2_norm\" width=\"600\"/></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we undersampled the training data, compared to when we oversampled the training data, we observed an improvement in the recall score of the positive class. Since there was less data, we were able to train the KNN and SVM models. Both the KNN and SVM models show good recall scores for the positive class, with the SVM model reaching **93.88%**. However, the best model of the four is the logistic regression model. While it has the same recall score as the SVM model for the positive class, it performs better in classifying the negative class (non-fraud transactions), giving the logistic regression model a slight edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Mixed Sampling\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>4 - Mixed Sampling (7192 Data Points)</th>\n",
    "    <th>4 - Mixed Sampling (Normalized, 7192 Data Points)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"plots/4_mix_sampling_7192.png?v=3\" alt=\"4_7192\" width=\"600\"/></td>\n",
    "    <td><img src=\"plots/4_mix_sampling_norm_7192.png?v=3\" alt=\"4_norm_7192\" width=\"600\"/></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 20 models were developed from the 5 differently sampled training datasets, containing: 227450, 71926, 22744, 7192, and 2274 training datapoints (50%, 15.81%, 5%, 1.581%, 0.5%, of oversampled training dataset). To recap, the positive class was oversampled, and the negative class was undersampled in order to reach a 50-50 class balance. The objective of this method was to find a middle ground where we could maximize the benefits of both undersampling and oversampling to develop the most robust training dataset.\n",
    "\n",
    "I have picked out the best peforming training set, the 1.581% (7192 datapoints) training set. The model with the highest recall on the positive class was the logistic regression model with a recall of **93.88%**, only incorrectly classifying 6 fraudulent transactions. It has the same recall score on the positive class as the undersampled logistic regression model, but has a better overall recall score since its recall score on the negative class is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Mixed Sampling + Outliers Removed\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>5 - Mixed Sampling, Outliers Removed (7192 Data Points)</th>\n",
    "    <th>5 - Mixed Sampling, Outliers Removed(Normalized, 7192 Data Points)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"plots/5_filtered_sampling_7192.png?v=3\" alt=\"5_7192\" width=\"600\"/></td>\n",
    "    <td><img src=\"plots/5_filtered_sampling_norm_7192.png?v=3\" alt=\"5_norm_7192\" width=\"600\"/></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed around 1% of the negative class datapoints that were deemed to be outliers. With some outliers removed from the training set, we get similiar results when we had outliers in the training data, almost unchanged. The only confusion matrix with any change was the decision trees confusion matrix, going a recall score of **86.73%** to **87.76%**.The other confusion matrices are all identical to the models trained with outliers in the dataset. This suggests that the models were able to create similiar or almost identical decision boundaries even with outliers removed. \n",
    "\n",
    "### Best Model\n",
    "\n",
    "From our confusion matrices, we can say that the best models were the **logistic regression models trained on 7192 training points with and without outliers**. They have the exact same results on the test data, suggesting that removal outliers had a minimal impact on improving classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves\n",
    "\n",
    "To better understand the difference between the two logistic regression models, we can plot an ROC curve to determine the change in the true positive rate (TPR) and the false positive rate (FPR). Doing so gives a complete picture of model performance across all possible decision thresholds, not just one. The ROC curve is not affected by class imbalance since it looks at the rates instead of raw counts. The ROC curve also gives us a scalar metric called AUC (Area Under the Curve) to summarize model performance across all thresholds. A higher AUC implies better overall model performance.\n",
    "\n",
    "ROC curves require probabilities instead of straight 0 and 1 labels, so we have to re-evaluate on the test data to output class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# get probabilities for the positive class\n",
    "logistic_4_preds = results_4_3['Logistic Regression'][0].predict_proba(xtest)[:, 1]\n",
    "logistic_5_preds = results_5_3['Logistic Regression'][0].predict_proba(xtest)[:, 1]\n",
    "\n",
    "# false positive rate and true positive rate\n",
    "fpr1, tpr1, _ = roc_curve(ytest, logistic_4_preds, pos_label=1)\n",
    "fpr2, tpr2, _ = roc_curve(ytest, logistic_5_preds, pos_label=1)\n",
    "\n",
    "ax1.plot(fpr1, tpr1, label='With Outliers AUC: {:.4f}'.format(roc_auc_score(ytest, logistic_4_preds)), alpha=0.6)\n",
    "ax1.plot(fpr2, tpr2, label='Without Outliers AUC: {:.4f}'.format(roc_auc_score(ytest, logistic_5_preds)), alpha=0.6)\n",
    "\n",
    "ax1.set_title('ROC Curve')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that the ROC curves and confusion matrices are identical suggests that removing outliers had little or no impact on the logistic regression models' ability to distinguish between fraudulent and non-fraudulent transactions. The outliers removed did not strongly influence classification, suggesting that outlier removal may not always lead to performance improvement. This may not always be the case however, it may just so happen for this test set or trained model that the results were identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We determined that the data imbalance would be a challenge that needed to solved in order to achieve satisfactory training results. Through initial investigations from the data exploration and preperation, 5 sampling methods were proposed to see how models would train on each respective method and how the evaluation results on the test data would turn out. As a reminder, here are the 5 sampling methods:\n",
    "\n",
    "1. No Balancing at All\n",
    "2. Undersampling\n",
    "3. Oversampling\n",
    "4. Undersampling + Oversampling\n",
    "5. Undersampling + Oversampling + Outlier Removal\n",
    "\n",
    "Through model evaluation using confusion matrices and ROC curves, it was determined that the **logistic regression model** trained with **mixed sampling** (undersampling and oversampling) on **7192** training data points yielded the best results based on confusion matrices. \n",
    "\n",
    "It was also determined that while in theory removing outliers would yield better training results, there was a minimal to zero impact on the final logistic regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Work\n",
    "\n",
    "Although the final recall of the logistic regression model was the highest, there were still 6 fraud cases that were not classified corrected by the model. In order to achieve models with even higher recall scores, more hyperparameter tuning using a more comprehensive grid search would allow the creation of the best version of the logistic regression model.\n",
    "\n",
    "In theory, support vector machines are a better version of logistic regression models since they can also handle non-linear data with various kernals. Due to computational limitations, hyperparameter tuning for the SVM model was not as comprehensive as it could have been, and we were unable to train SVM models on the larger training datasets. Another possible model choice to further explore would be neural networks, but would require more computational resources and careful architecture choice since neural networks are highly customizable.\n",
    "\n",
    "More work could also have been done on the data sampling to improve training data. Other oversampling methods such as ADASYN (Adaptive Synthetic Sampling) could have been used to focus on harder to learn datapoints. A more comprehensive outlier removal process might also allow for better model generalization and less overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
